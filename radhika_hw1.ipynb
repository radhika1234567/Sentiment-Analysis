{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: nltk in c:\\users\\14699\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (3.5)\n",
      "Requirement already satisfied: tqdm in c:\\users\\14699\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from nltk) (4.48.2)\n",
      "Requirement already satisfied: joblib in c:\\users\\14699\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from nltk) (0.14.1)\n",
      "Requirement already satisfied: regex in c:\\users\\14699\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from nltk) (2020.7.14)\n",
      "Requirement already satisfied: click in c:\\users\\14699\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from nltk) (7.1.2)"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: You are using pip version 20.1; however, version 20.2.2 is available.\n",
      "You should consider upgrading via the 'c:\\users\\14699\\appdata\\local\\programs\\python\\python38\\python.exe -m pip install --upgrade pip' command.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Requirement already satisfied: spacy in c:\\users\\14699\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (2.3.2)\n",
      "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in c:\\users\\14699\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from spacy) (2.0.3)\n",
      "Requirement already satisfied: srsly<1.1.0,>=1.0.2 in c:\\users\\14699\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from spacy) (1.0.2)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.13.0 in c:\\users\\14699\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from spacy) (2.23.0)\n",
      "Requirement already satisfied: blis<0.5.0,>=0.4.0 in c:\\users\\14699\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from spacy) (0.4.1)\n",
      "Requirement already satisfied: plac<1.2.0,>=0.9.6 in c:\\users\\14699\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from spacy) (1.1.3)\n",
      "Requirement already satisfied: catalogue<1.1.0,>=0.0.7 in c:\\users\\14699\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from spacy) (1.0.0)\n",
      "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in c:\\users\\14699\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from spacy) (3.0.2)\n",
      "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in c:\\users\\14699\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from spacy) (1.0.2)\n",
      "Requirement already satisfied: numpy>=1.15.0 in c:\\users\\14699\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from spacy) (1.18.2)\n",
      "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in c:\\users\\14699\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from spacy) (4.48.2)\n",
      "Requirement already satisfied: wasabi<1.1.0,>=0.4.0 in c:\\users\\14699\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from spacy) (0.8.0)\n",
      "Requirement already satisfied: thinc==7.4.1 in c:\\users\\14699\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from spacy) (7.4.1)\n",
      "Requirement already satisfied: setuptools in c:\\users\\14699\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from spacy) (41.2.0)\n",
      "Requirement already satisfied: idna<3,>=2.5 in c:\\users\\14699\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy) (2.9)\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in c:\\users\\14699\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy) (1.25.9)\n",
      "Requirement already satisfied: chardet<4,>=3.0.2 in c:\\users\\14699\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy) (3.0.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\14699\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy) (2020.4.5.1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: You are using pip version 20.1; however, version 20.2.2 is available.\n",
      "You should consider upgrading via the 'c:\\users\\14699\\appdata\\local\\programs\\python\\python38\\python.exe -m pip install --upgrade pip' command.\n",
      "WARNING: You are using pip version 20.1; however, version 20.2.2 is available.\n",
      "You should consider upgrading via the 'c:\\users\\14699\\appdata\\local\\programs\\python\\python38\\python.exe -m pip install --upgrade pip' command.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: stopwords in c:\\users\\14699\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (0.1.3)\n"
     ]
    }
   ],
   "source": [
    "!pip install nltk\n",
    "!pip install spacy\n",
    "!pip install stopwords\n",
    "import nltk\n",
    "import spacy\n",
    "import numpy as np\n",
    "from nltk.tokenize import TreebankWordTokenizer\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.corpus import wordnet\n",
    "#from TokenizationTest import TokenizationTest\n",
    "from happyfuntokenizing import Tokenizer as potts\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn import preprocessing\n",
    "from sklearn import linear_model\n",
    "import pandas as pd\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "porter_stemmer = PorterStemmer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: wordcloud in c:\\users\\14699\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (1.8.0)\n",
      "Requirement already satisfied: matplotlib in c:\\users\\14699\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from wordcloud) (3.2.1)\n",
      "Requirement already satisfied: pillow in c:\\users\\14699\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from wordcloud) (7.1.1)\n",
      "Requirement already satisfied: numpy>=1.6.1 in c:\\users\\14699\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from wordcloud) (1.18.2)\n",
      "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in c:\\users\\14699\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from matplotlib->wordcloud) (2.4.6)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in c:\\users\\14699\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from matplotlib->wordcloud) (1.2.0)\n",
      "Requirement already satisfied: python-dateutil>=2.1 in c:\\users\\14699\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from matplotlib->wordcloud) (2.8.1)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\users\\14699\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from matplotlib->wordcloud) (0.10.0)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\14699\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from python-dateutil>=2.1->matplotlib->wordcloud) (1.14.0)"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: You are using pip version 20.1; however, version 20.2.2 is available.\n",
      "You should consider upgrading via the 'c:\\users\\14699\\appdata\\local\\programs\\python\\python38\\python.exe -m pip install --upgrade pip' command.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: You are using pip version 20.1; however, version 20.2.2 is available.\n",
      "You should consider upgrading via the 'c:\\users\\14699\\appdata\\local\\programs\\python\\python38\\python.exe -m pip install --upgrade pip' command.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: gensim in c:\\users\\14699\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (3.8.3)\n",
      "Requirement already satisfied: six>=1.5.0 in c:\\users\\14699\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from gensim) (1.14.0)\n",
      "Requirement already satisfied: smart-open>=1.8.1 in c:\\users\\14699\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from gensim) (2.1.1)\n",
      "Requirement already satisfied: Cython==0.29.14 in c:\\users\\14699\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from gensim) (0.29.14)\n",
      "Requirement already satisfied: numpy>=1.11.3 in c:\\users\\14699\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from gensim) (1.18.2)\n",
      "Requirement already satisfied: scipy>=0.18.1 in c:\\users\\14699\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from gensim) (1.4.1)\n",
      "Requirement already satisfied: boto in c:\\users\\14699\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from smart-open>=1.8.1->gensim) (2.49.0)\n",
      "Requirement already satisfied: boto3 in c:\\users\\14699\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from smart-open>=1.8.1->gensim) (1.14.56)\n",
      "Requirement already satisfied: requests in c:\\users\\14699\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from smart-open>=1.8.1->gensim) (2.23.0)\n",
      "Requirement already satisfied: botocore<1.18.0,>=1.17.56 in c:\\users\\14699\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from boto3->smart-open>=1.8.1->gensim) (1.17.56)\n",
      "Requirement already satisfied: jmespath<1.0.0,>=0.7.1 in c:\\users\\14699\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from boto3->smart-open>=1.8.1->gensim) (0.10.0)\n",
      "Requirement already satisfied: s3transfer<0.4.0,>=0.3.0 in c:\\users\\14699\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from boto3->smart-open>=1.8.1->gensim) (0.3.3)\n",
      "Requirement already satisfied: chardet<4,>=3.0.2 in c:\\users\\14699\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from requests->smart-open>=1.8.1->gensim) (3.0.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\14699\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from requests->smart-open>=1.8.1->gensim) (2020.4.5.1)\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in c:\\users\\14699\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from requests->smart-open>=1.8.1->gensim) (1.25.9)\n",
      "Requirement already satisfied: idna<3,>=2.5 in c:\\users\\14699\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from requests->smart-open>=1.8.1->gensim) (2.9)\n",
      "Requirement already satisfied: docutils<0.16,>=0.10 in c:\\users\\14699\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from botocore<1.18.0,>=1.17.56->boto3->smart-open>=1.8.1->gensim) (0.15.2)\n",
      "Requirement already satisfied: python-dateutil<3.0.0,>=2.1 in c:\\users\\14699\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from botocore<1.18.0,>=1.17.56->boto3->smart-open>=1.8.1->gensim) (2.8.1)\n"
     ]
    }
   ],
   "source": [
    "!pip install wordcloud\n",
    "!pip install gensim\n",
    "import pandas as pd\n",
    "import re\n",
    "import string\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize \n",
    "from nltk.stem.porter import PorterStemmer\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from collections import Counter\n",
    "from wordcloud import WordCloud, STOPWORDS\n",
    "import matplotlib.pyplot as plt\n",
    "from gensim.models import ldamodel\n",
    "import gensim.corpora\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
    "from nltk import pos_tag,word_tokenize\n",
    "\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "porter_stemmer = PorterStemmer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>text</th>\n",
       "      <th>Target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>@USAirways  ! THE WORST in customer service. @...</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>@united call wait times are over 20 minutes an...</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>@JetBlue what's up with the random delay on fl...</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>@AmericanAir Good morning!  Wondering why my p...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>@united UA 746. Pacific Rim and Date Night cut...</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Id                                               text  Target\n",
       "0   1  @USAirways  ! THE WORST in customer service. @...      -1\n",
       "1   2  @united call wait times are over 20 minutes an...      -1\n",
       "2   3  @JetBlue what's up with the random delay on fl...      -1\n",
       "3   4  @AmericanAir Good morning!  Wondering why my p...       0\n",
       "4   5  @united UA 746. Pacific Rim and Date Night cut...      -1"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train = pd.read_csv('train.csv', encoding = 'latin-1')\n",
    "df_train.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-1    4566\n",
       " 0    1536\n",
       " 1    1218\n",
       "Name: Target, dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train[\"Target\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7320, 3)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7322</td>\n",
       "      <td>@AmericanAir In car gng to DFW. Pulled over 1h...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>7323</td>\n",
       "      <td>@AmericanAir after all, the plane didnÛªt lan...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>7324</td>\n",
       "      <td>@SouthwestAir can't believe how many paying cu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>7325</td>\n",
       "      <td>@USAirways I can legitimately say that I would...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7326</td>\n",
       "      <td>@AmericanAir still no response from AA. great ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     id                                               text\n",
       "0  7322  @AmericanAir In car gng to DFW. Pulled over 1h...\n",
       "1  7323  @AmericanAir after all, the plane didnÛªt lan...\n",
       "2  7324  @SouthwestAir can't believe how many paying cu...\n",
       "3  7325  @USAirways I can legitimately say that I would...\n",
       "4  7326  @AmericanAir still no response from AA. great ..."
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test = pd.read_csv('test.csv')\n",
    "df_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7320, 2)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## data cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined = df_train.append(df_test,ignore_index= True )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>text</th>\n",
       "      <th>Target</th>\n",
       "      <th>id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.0</td>\n",
       "      <td>@USAirways  ! THE WORST in customer service. @...</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2.0</td>\n",
       "      <td>@united call wait times are over 20 minutes an...</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3.0</td>\n",
       "      <td>@JetBlue what's up with the random delay on fl...</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.0</td>\n",
       "      <td>@AmericanAir Good morning!  Wondering why my p...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.0</td>\n",
       "      <td>@united UA 746. Pacific Rim and Date Night cut...</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Id                                               text  Target  id\n",
       "0  1.0  @USAirways  ! THE WORST in customer service. @...    -1.0 NaN\n",
       "1  2.0  @united call wait times are over 20 minutes an...    -1.0 NaN\n",
       "2  3.0  @JetBlue what's up with the random delay on fl...    -1.0 NaN\n",
       "3  4.0  @AmericanAir Good morning!  Wondering why my p...     0.0 NaN\n",
       "4  5.0  @united UA 746. Pacific Rim and Date Night cut...    -1.0 NaN"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "combined.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(14640, 4)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "combined.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_pattern(text,pattern):\n",
    "    text = text.lower()\n",
    "    r = re.findall(pattern,text)\n",
    "    for i in r:\n",
    "        text = re.sub(i,\"\",text)\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined[\"tidy_tweet\"] = np.vectorize(remove_pattern)(combined[\"text\"], \"@[\\w]*\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined[\"tidy_tweet\"] = combined[\"tidy_tweet\"].str.replace(\"[^a-zA-Z#]\",\" \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined['tidy_tweet'] = combined['tidy_tweet'].apply(lambda x: ' '.join([w for w in x.split() if len(w)>3]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>text</th>\n",
       "      <th>Target</th>\n",
       "      <th>id</th>\n",
       "      <th>tidy_tweet</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.0</td>\n",
       "      <td>@USAirways  ! THE WORST in customer service. @...</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>worst customer service calling over month book...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2.0</td>\n",
       "      <td>@united call wait times are over 20 minutes an...</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>call wait times over minutes airport wait time...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3.0</td>\n",
       "      <td>@JetBlue what's up with the random delay on fl...</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>what with random delay flight chance being fal...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.0</td>\n",
       "      <td>@AmericanAir Good morning!  Wondering why my p...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>good morning wondering check boarding pass thi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.0</td>\n",
       "      <td>@united UA 746. Pacific Rim and Date Night cut...</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>pacific date night constantly randomly spot re...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Id                                               text  Target  id  \\\n",
       "0  1.0  @USAirways  ! THE WORST in customer service. @...    -1.0 NaN   \n",
       "1  2.0  @united call wait times are over 20 minutes an...    -1.0 NaN   \n",
       "2  3.0  @JetBlue what's up with the random delay on fl...    -1.0 NaN   \n",
       "3  4.0  @AmericanAir Good morning!  Wondering why my p...     0.0 NaN   \n",
       "4  5.0  @united UA 746. Pacific Rim and Date Night cut...    -1.0 NaN   \n",
       "\n",
       "                                          tidy_tweet  \n",
       "0  worst customer service calling over month book...  \n",
       "1  call wait times over minutes airport wait time...  \n",
       "2  what with random delay flight chance being fal...  \n",
       "3  good morning wondering check boarding pass thi...  \n",
       "4  pacific date night constantly randomly spot re...  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "combined.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### tokenization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    [worst, customer, service, calling, over, mont...\n",
       "1    [call, wait, times, over, minutes, airport, wa...\n",
       "2    [what, with, random, delay, flight, chance, be...\n",
       "3    [good, morning, wondering, check, boarding, pa...\n",
       "4    [pacific, date, night, constantly, randomly, s...\n",
       "Name: tidy_tweet, dtype: object"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenised_tweet = combined['tidy_tweet'].apply(lambda x: x.split())\n",
    "tokenised_tweet.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    [worst, custom, servic, call, over, month, boo...\n",
       "1    [call, wait, time, over, minut, airport, wait,...\n",
       "2    [what, with, random, delay, flight, chanc, be,...\n",
       "3    [good, morn, wonder, check, board, pass, thi, ...\n",
       "4    [pacif, date, night, constantli, randomli, spo...\n",
       "Name: tidy_tweet, dtype: object"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk.stem.porter import PorterStemmer \n",
    "stemmer = PorterStemmer()\n",
    "tokenised_tweet = tokenised_tweet.apply(lambda x: [stemmer.stem(i) for i in x])\n",
    "tokenised_tweet.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lemmatization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\14699\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0    [worst, custom, servic, call, over, month, boo...\n",
       "1    [call, wait, time, over, minut, airport, wait,...\n",
       "2    [what, with, random, delay, flight, chanc, be,...\n",
       "3    [good, morn, wonder, check, board, pas, thi, m...\n",
       "4    [pacif, date, night, constantli, randomli, spo...\n",
       "Name: tidy_tweet, dtype: object"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('wordnet')\n",
    "from nltk.stem import WordNetLemmatizer \n",
    "lemmatizer = WordNetLemmatizer()\n",
    "tokenised_tweet = tokenised_tweet.apply(lambda x: [lemmatizer.lemmatize(i) for i in x])\n",
    "tokenised_tweet.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(tokenised_tweet)):\n",
    "    tokenised_tweet[i] = ' '.join(tokenised_tweet[i])\n",
    "    \n",
    "combined['tidy_tweet'] = tokenised_tweet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>text</th>\n",
       "      <th>Target</th>\n",
       "      <th>id</th>\n",
       "      <th>tidy_tweet</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.0</td>\n",
       "      <td>@USAirways  ! THE WORST in customer service. @...</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>worst custom servic call over month book fligh...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2.0</td>\n",
       "      <td>@united call wait times are over 20 minutes an...</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>call wait time over minut airport wait time lo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3.0</td>\n",
       "      <td>@JetBlue what's up with the random delay on fl...</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>what with random delay flight chanc be fals alarm</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.0</td>\n",
       "      <td>@AmericanAir Good morning!  Wondering why my p...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>good morn wonder check board pas thi morn</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.0</td>\n",
       "      <td>@united UA 746. Pacific Rim and Date Night cut...</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>pacif date night constantli randomli spot repeat</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Id                                               text  Target  id  \\\n",
       "0  1.0  @USAirways  ! THE WORST in customer service. @...    -1.0 NaN   \n",
       "1  2.0  @united call wait times are over 20 minutes an...    -1.0 NaN   \n",
       "2  3.0  @JetBlue what's up with the random delay on fl...    -1.0 NaN   \n",
       "3  4.0  @AmericanAir Good morning!  Wondering why my p...     0.0 NaN   \n",
       "4  5.0  @united UA 746. Pacific Rim and Date Night cut...    -1.0 NaN   \n",
       "\n",
       "                                          tidy_tweet  \n",
       "0  worst custom servic call over month book fligh...  \n",
       "1  call wait time over minut airport wait time lo...  \n",
       "2  what with random delay flight chanc be fals alarm  \n",
       "3          good morn wonder check board pas thi morn  \n",
       "4   pacif date night constantli randomli spot repeat  "
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "combined.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(14640, 5)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "combined.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extracting Features from Cleaned Tweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: You are using pip version 20.1; however, version 20.2.2 is available.\n",
      "You should consider upgrading via the 'c:\\users\\14699\\appdata\\local\\programs\\python\\python38\\python.exe -m pip install --upgrade pip' command.\n",
      "c:\\users\\14699\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\sklearn\\externals\\six.py:28: FutureWarning: The module is deprecated in version 0.21 and will be removed in version 0.23 since we've dropped support for Python 2.7. Please rely on the official version of six (https://pypi.org/project/six/).\n",
      "  warnings.warn(\"The module is deprecated in version 0.21 and will be removed \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: mglearn in c:\\users\\14699\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (0.1.7)\n",
      "Requirement already satisfied: numpy in c:\\users\\14699\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from mglearn) (1.18.2)\n",
      "Requirement already satisfied: matplotlib in c:\\users\\14699\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from mglearn) (3.2.1)\n",
      "Requirement already satisfied: scikit-learn in c:\\users\\14699\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from mglearn) (0.22.2.post1)\n",
      "Requirement already satisfied: pandas in c:\\users\\14699\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from mglearn) (1.0.3)\n",
      "Requirement already satisfied: pillow in c:\\users\\14699\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from mglearn) (7.1.1)\n",
      "Requirement already satisfied: cycler in c:\\users\\14699\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from mglearn) (0.10.0)\n",
      "Requirement already satisfied: imageio in c:\\users\\14699\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from mglearn) (2.8.0)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in c:\\users\\14699\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from matplotlib->mglearn) (1.2.0)\n",
      "Requirement already satisfied: python-dateutil>=2.1 in c:\\users\\14699\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from matplotlib->mglearn) (2.8.1)\n",
      "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in c:\\users\\14699\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from matplotlib->mglearn) (2.4.6)\n",
      "Requirement already satisfied: joblib>=0.11 in c:\\users\\14699\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from scikit-learn->mglearn) (0.14.1)\n",
      "Requirement already satisfied: scipy>=0.17.0 in c:\\users\\14699\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from scikit-learn->mglearn) (1.4.1)\n",
      "Requirement already satisfied: pytz>=2017.2 in c:\\users\\14699\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from pandas->mglearn) (2019.3)\n",
      "Requirement already satisfied: six in c:\\users\\14699\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from cycler->mglearn) (1.14.0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\14699\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\sklearn\\externals\\joblib\\__init__.py:15: FutureWarning: sklearn.externals.joblib is deprecated in 0.21 and will be removed in 0.23. Please import this functionality directly from joblib, which can be installed with: pip install joblib. If this warning is raised when loading pickled models, you may need to re-serialize those models with scikit-learn 0.21+.\n",
      "  warnings.warn(msg, category=FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "!pip install mglearn\n",
    "%matplotlib inline\n",
    "from preamble import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
    "import gensim"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bag-of-Words Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(14640, 1000)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bow_vect = CountVectorizer(max_df=0.90, min_df=5,max_features=1000, stop_words='english')\n",
    "bow = bow_vect.fit_transform(combined['tidy_tweet'])\n",
    "bow.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dense representation of bow:\n",
      "[[0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " ...\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]]\n"
     ]
    }
   ],
   "source": [
    "print(\"Dense representation of bow:\\n{}\".format(\n",
    "    bow.toarray()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TF-IDF Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(14640, 1000)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "tfidf_vectorizer = TfidfVectorizer(max_df=0.90, min_df=5, max_features=1000, stop_words='english')\n",
    "# TF-IDF feature matrix\n",
    "tfidf = tfidf_vectorizer.fit_transform(combined['tidy_tweet'])\n",
    "tfidf.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.preprocessing import MaxAbsScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_bow = bow[:7320,:]\n",
    "test_bow = bow[7320:,:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## splitting datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\14699\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:938: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=10, class_weight=None, dual=False, fit_intercept=True,\n",
       "                   intercept_scaling=1, l1_ratio=None, max_iter=100,\n",
       "                   multi_class='auto', n_jobs=None, penalty='l2',\n",
       "                   random_state=100, solver='lbfgs', tol=0.0001, verbose=0,\n",
       "                   warm_start=False)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "xtrain_bow, xvalid_bow, ytrain, yvalid = train_test_split(train_bow,df_train['Target'], random_state=42,test_size=0.2)\n",
    "lreg = LogisticRegression(C = 10, random_state=100)\n",
    "lreg.fit(xtrain_bow, ytrain)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean cross-validation accuracy: 0.75\n"
     ]
    }
   ],
   "source": [
    "scores = cross_val_score(LogisticRegression(), xtrain_bow, ytrain, cv=5)\n",
    "print(\"Mean cross-validation accuracy: {:.2f}\".format(np.mean(scores)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best cross-validation score: 0.75\n",
      "Best parameters:  {'C': 1}\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "param_grid = {'C': [0.001, 0.01, 0.1, 1, 10]}\n",
    "grid = GridSearchCV(LogisticRegression(max_iter=1000), param_grid, cv=5)\n",
    "grid.fit(xtrain_bow, ytrain)\n",
    "print(\"Best cross-validation score: {:.2f}\".format(grid.best_score_))\n",
    "print(\"Best parameters: \", grid.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = pd.DataFrame(xvalid_bow)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>(0, 951)\\t1\\n  (0, 487)\\t1\\n  (0, 476)\\t1\\n ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>(0, 880)\\t1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>(0, 211)\\t1\\n  (0, 280)\\t1\\n  (0, 309)\\t1\\n ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>(0, 346)\\t2\\n  (0, 892)\\t1\\n  (0, 8)\\t1\\n  (...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>(0, 121)\\t2\\n  (0, 480)\\t1\\n  (0, 711)\\t1\\n ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   0\n",
       "0    (0, 951)\\t1\\n  (0, 487)\\t1\\n  (0, 476)\\t1\\n ...\n",
       "1                                        (0, 880)\\t1\n",
       "2    (0, 211)\\t1\\n  (0, 280)\\t1\\n  (0, 309)\\t1\\n ...\n",
       "3    (0, 346)\\t2\\n  (0, 892)\\t1\\n  (0, 8)\\t1\\n  (...\n",
       "4    (0, 121)\\t2\\n  (0, 480)\\t1\\n  (0, 711)\\t1\\n ..."
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Building model using Bag-of-Words features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### logistic regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6860677457420673"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prediction = lreg.predict(xvalid_bow) # predicting on the validation set\n",
    "f1_score(yvalid, prediction,average='macro') # calculating f1 score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_pred = lreg.predict(test_bow)\n",
    "df_test['Target'] = test_pred\n",
    "submission = df_test[['id','Target']]\n",
    "submission.to_csv('3hw1_radhika.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>text</th>\n",
       "      <th>Target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7322</td>\n",
       "      <td>@AmericanAir In car gng to DFW. Pulled over 1h...</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>7323</td>\n",
       "      <td>@AmericanAir after all, the plane didnÛªt lan...</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>7324</td>\n",
       "      <td>@SouthwestAir can't believe how many paying cu...</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>7325</td>\n",
       "      <td>@USAirways I can legitimately say that I would...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7326</td>\n",
       "      <td>@AmericanAir still no response from AA. great ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     id                                               text  Target\n",
       "0  7322  @AmericanAir In car gng to DFW. Pulled over 1h...      -1\n",
       "1  7323  @AmericanAir after all, the plane didnÛªt lan...      -1\n",
       "2  7324  @SouthwestAir can't believe how many paying cu...      -1\n",
       "3  7325  @USAirways I can legitimately say that I would...       0\n",
       "4  7326  @AmericanAir still no response from AA. great ...       1"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Building model using TF-IDF features\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_tfidf = tfidf[:7320,:]\n",
    "test_tfidf = tfidf[7320:,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\14699\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:938: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.6949240173032875"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xtrain_tfidf = train_tfidf[ytrain.index]\n",
    "xvalid_tfidf = train_tfidf[yvalid.index]\n",
    "classifier = lreg.fit(xtrain_tfidf, ytrain)\n",
    "prediction = classifier.predict(xvalid_tfidf)\n",
    "f1_score(yvalid, prediction,average='macro')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_pred = lreg.predict(test_bow)\n",
    "df_test['Target'] = test_pred\n",
    "#submission = df_test[['id','Target']]\n",
    "#submission.to_csv('2hw1_radhika.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>text</th>\n",
       "      <th>Target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7322</td>\n",
       "      <td>@AmericanAir In car gng to DFW. Pulled over 1h...</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>7323</td>\n",
       "      <td>@AmericanAir after all, the plane didnÛªt lan...</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>7324</td>\n",
       "      <td>@SouthwestAir can't believe how many paying cu...</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>7325</td>\n",
       "      <td>@USAirways I can legitimately say that I would...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7326</td>\n",
       "      <td>@AmericanAir still no response from AA. great ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     id                                               text  Target\n",
       "0  7322  @AmericanAir In car gng to DFW. Pulled over 1h...      -1\n",
       "1  7323  @AmericanAir after all, the plane didnÛªt lan...      -1\n",
       "2  7324  @SouthwestAir can't believe how many paying cu...      -1\n",
       "3  7325  @USAirways I can legitimately say that I would...       0\n",
       "4  7326  @AmericanAir still no response from AA. great ...       1"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## XGBOOST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: xgboost in c:\\users\\14699\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (1.2.0)\n",
      "Requirement already satisfied: scipy in c:\\users\\14699\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from xgboost) (1.4.1)\n",
      "Requirement already satisfied: numpy in c:\\users\\14699\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from xgboost) (1.18.2)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: You are using pip version 20.1; however, version 20.2.2 is available.\n",
      "You should consider upgrading via the 'c:\\users\\14699\\appdata\\local\\programs\\python\\python38\\python.exe -m pip install --upgrade pip' command.\n"
     ]
    }
   ],
   "source": [
    "!pip install xgboost\n",
    "from xgboost import XGBClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Building model using Bag-of-Words features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7037498791701974"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xgb_model = XGBClassifier(max_depth=6, n_estimators=1000).fit(xtrain_bow, ytrain)\n",
    "prediction = xgb_model.predict(xvalid_bow)\n",
    "f1_score(yvalid, prediction,average='macro')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<bound method NDFrame.head of          id                                               text  Target\n",
       "0      7322  @AmericanAir In car gng to DFW. Pulled over 1h...      -1\n",
       "1      7323  @AmericanAir after all, the plane didnÛªt lan...      -1\n",
       "2      7324  @SouthwestAir can't believe how many paying cu...      -1\n",
       "3      7325  @USAirways I can legitimately say that I would...       0\n",
       "4      7326  @AmericanAir still no response from AA. great ...      -1\n",
       "...     ...                                                ...     ...\n",
       "7315  14637  @JetBlue Traveling with two kids tomorrow (age...       0\n",
       "7316  14638  @JetBlue Tx for the info. Just don't understan...       0\n",
       "7317  14639  @AmericanAir I understand. But why is this the...      -1\n",
       "7318  14640                               @USAirways really!??      -1\n",
       "7319  14641  @united no I did not make connection.  Your st...      -1\n",
       "\n",
       "[7320 rows x 3 columns]>"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_pred = xgb_model.predict(test_bow)\n",
    "df_test['Target'] = test_pred\n",
    "df_test.head"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6625341547342201"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xgb = XGBClassifier(max_depth=6, n_estimators=1000).fit(xtrain_tfidf, ytrain)\n",
    "prediction = xgb.predict(xvalid_tfidf)\n",
    "f1_score(yvalid, prediction,average='macro')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<bound method NDFrame.head of          id                                               text  Target\n",
       "0      7322  @AmericanAir In car gng to DFW. Pulled over 1h...      -1\n",
       "1      7323  @AmericanAir after all, the plane didnÛªt lan...      -1\n",
       "2      7324  @SouthwestAir can't believe how many paying cu...      -1\n",
       "3      7325  @USAirways I can legitimately say that I would...       0\n",
       "4      7326  @AmericanAir still no response from AA. great ...       1\n",
       "...     ...                                                ...     ...\n",
       "7315  14637  @JetBlue Traveling with two kids tomorrow (age...      -1\n",
       "7316  14638  @JetBlue Tx for the info. Just don't understan...      -1\n",
       "7317  14639  @AmericanAir I understand. But why is this the...      -1\n",
       "7318  14640                               @USAirways really!??      -1\n",
       "7319  14641  @united no I did not make connection.  Your st...      -1\n",
       "\n",
       "[7320 rows x 3 columns]>"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_pred = xgb.predict(test_tfidf)\n",
    "df_test['Target'] = test_pred\n",
    "df_test.head"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Naive bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR: Could not find a version that satisfies the requirement MultinomialNB (from versions: none)\n",
      "ERROR: No matching distribution found for MultinomialNB\n",
      "WARNING: You are using pip version 20.1; however, version 20.2.2 is available.\n",
      "You should consider upgrading via the 'c:\\users\\14699\\appdata\\local\\programs\\python\\python38\\python.exe -m pip install --upgrade pip' command.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.6856321965642644"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "!pip install MultinomialNB\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "classifier = MultinomialNB(alpha=0.1).fit(xtrain_bow, ytrain)\n",
    "prediction = classifier.predict(xvalid_bow)\n",
    "f1_score(yvalid, prediction,average='macro')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Building model using Bag-of-Words features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<bound method NDFrame.head of          id                                               text  Target\n",
       "0      7322  @AmericanAir In car gng to DFW. Pulled over 1h...      -1\n",
       "1      7323  @AmericanAir after all, the plane didnÛªt lan...      -1\n",
       "2      7324  @SouthwestAir can't believe how many paying cu...      -1\n",
       "3      7325  @USAirways I can legitimately say that I would...       0\n",
       "4      7326  @AmericanAir still no response from AA. great ...       1\n",
       "...     ...                                                ...     ...\n",
       "7315  14637  @JetBlue Traveling with two kids tomorrow (age...       0\n",
       "7316  14638  @JetBlue Tx for the info. Just don't understan...      -1\n",
       "7317  14639  @AmericanAir I understand. But why is this the...      -1\n",
       "7318  14640                               @USAirways really!??      -1\n",
       "7319  14641  @united no I did not make connection.  Your st...      -1\n",
       "\n",
       "[7320 rows x 3 columns]>"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_pred = classifier.predict(test_bow)\n",
    "df_test['Target'] = test_pred\n",
    "df_test.head"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6230551397379698"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier = MultinomialNB(alpha=0.1).fit(xtrain_tfidf, ytrain)\n",
    "prediction = classifier.predict(xvalid_tfidf)\n",
    "f1_score(yvalid, prediction,average='macro')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<bound method NDFrame.head of          id                                               text  Target  target\n",
       "0      7322  @AmericanAir In car gng to DFW. Pulled over 1h...      -1      -1\n",
       "1      7323  @AmericanAir after all, the plane didnÛªt lan...      -1      -1\n",
       "2      7324  @SouthwestAir can't believe how many paying cu...      -1      -1\n",
       "3      7325  @USAirways I can legitimately say that I would...       0       0\n",
       "4      7326  @AmericanAir still no response from AA. great ...       1       1\n",
       "...     ...                                                ...     ...     ...\n",
       "7315  14637  @JetBlue Traveling with two kids tomorrow (age...       0      -1\n",
       "7316  14638  @JetBlue Tx for the info. Just don't understan...      -1      -1\n",
       "7317  14639  @AmericanAir I understand. But why is this the...      -1      -1\n",
       "7318  14640                               @USAirways really!??      -1      -1\n",
       "7319  14641  @united no I did not make connection.  Your st...      -1      -1\n",
       "\n",
       "[7320 rows x 4 columns]>"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_pred = classifier.predict(test_tfidf)\n",
    "df_test['target'] = test_pred\n",
    "df_test.head"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
